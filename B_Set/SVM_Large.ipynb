{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import os\n",
    "\n",
    "t0 = time()\n",
    "##################\n",
    "\n",
    "# preprocess the image data for SVM classification \n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "### preload png image files in each folder\n",
    "\n",
    "\n",
    "filenames = []\n",
    "for e in os.walk('./small'):\n",
    "    filenames.append(e)\n",
    "  \n",
    "    \n",
    "foldername = filenames[0][1] # ['A','G','E','F',...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time cost to read files: 137.361000061\n",
      "images[A].shape = (1872L, 28L, 28L)\n",
      "images[B].shape = (1873L, 28L, 28L)\n",
      "images[C].shape = (1873L, 28L, 28L)\n",
      "images[D].shape = (1873L, 28L, 28L)\n",
      "images[E].shape = (1873L, 28L, 28L)\n",
      "images[F].shape = (1872L, 28L, 28L)\n",
      "images[G].shape = (1872L, 28L, 28L)\n",
      "images[H].shape = (1872L, 28L, 28L)\n",
      "images[I].shape = (1872L, 28L, 28L)\n",
      "images[J].shape = (1872L, 28L, 28L)\n",
      "Total datasets size\n",
      "===================\n",
      "n_samples: 18724\n",
      "n_features: 784\n",
      "n_classes: 10\n",
      "===================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = foldername\n",
    "\n",
    "filepath_dict = {foldername[i]:filenames[i+1][2]\n",
    "                     for i,_ in enumerate(foldername)}\n",
    "\n",
    "filepaths = defaultdict(list)\n",
    "for key in filepath_dict.keys():\n",
    "    filepaths[key] = [ os.path.join('./small',key,path) for path in filepath_dict[key]]\n",
    "    \n",
    "def imageData(key):\n",
    "    '''input:key, output list of image data '''\n",
    "    imagedata = []\n",
    "    for e in filepaths[key]:\n",
    "        try:\n",
    "            imagedata.append(pl.imread(e))\n",
    "        except:\n",
    "            pass\n",
    "    return np.array(imagedata)\n",
    "\n",
    "images = {key:imageData(key) for key in filepaths.keys()} # images['A'] \n",
    "\n",
    "print 'time cost to read files: {}'.format(time()-t0)\n",
    "size = 0\n",
    "for i in labels:\n",
    "    print \"images[{}].shape = {}\".format(i,images[i].shape)\n",
    "\n",
    "    size += images[i].shape[0]\n",
    "\n",
    "dataA = np.array([np.ndarray.flatten(images['A'][i]) for i in range(images['A'].shape[0])])\n",
    "\n",
    "h = images['A'].shape[-1]\n",
    "w = images['A'].shape[-2]\n",
    "n_features = h*w\n",
    "\n",
    "\n",
    "############################################\n",
    "\n",
    "# prepare \"data\" for machine learn X,\n",
    "\n",
    "# data.shape = (18724,28*28) \n",
    "\n",
    "# y -> label as (A,A,A....,G,G,H,H,H)\n",
    "\n",
    "#      size as (18724,) \n",
    "\n",
    "############################################\n",
    "\n",
    "\n",
    "data = np.zeros([size,n_features])\n",
    "temp=0\n",
    "y = np.chararray(size) # string numpy array\n",
    "\n",
    "\n",
    "for j,label in enumerate(labels):\n",
    "    for e in range(images[label].shape[0]):        \n",
    "        data[temp] = np.ndarray.flatten(images[label][e])        \n",
    "        y[temp]= np.array(label)\n",
    "        temp += 1\n",
    "\n",
    "X = data\n",
    "n_samples = data.shape[0]\n",
    "n_classes = len(labels)\n",
    "\n",
    "print \"Total datasets size\"\n",
    "print \"===================\"\n",
    "print \"n_samples: {}\".format(n_samples)\n",
    "print \"n_features: {}\".format(n_features)\n",
    "print \"n_classes: {}\".format(n_classes)\n",
    "print \"===================\"\n",
    "###########################################\n",
    "\n",
    "#\n",
    "\n",
    "# split train/test for our original data\n",
    "\n",
    "#\n",
    "\n",
    "#######################\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting the 150 eigenpixel from 784 pixels\n",
      "done in 1.638s\n",
      "Projecting the input data on the eigenimage orthonormal basis\n",
      "done in 0.125s\n",
      "# Tuning hyper-parameters for precision\n",
      "()\n",
      "# Tuning hyper-parameters for recall\n",
      "()\n",
      "Fitting the classifier to the training set\n"
     ]
    }
   ],
   "source": [
    "###############\n",
    "\n",
    "#\n",
    "\n",
    "#  PCA\n",
    "\n",
    "#\n",
    "\n",
    "###############\n",
    "\n",
    "\n",
    "n_components = 150\n",
    "\n",
    "print \"Extracting the %d eigenpixel from %d pixels\" % (n_components, X_train.shape[1])\n",
    "t0 = time()\n",
    "pca = PCA(n_components=n_components, whiten=True).fit(X_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "eigenimage = pca.components_.reshape((n_components, h, w))\n",
    "\n",
    "print \"Projecting the input data on the eigenimage orthonormal basis\"\n",
    "t0 = time()\n",
    "X_train_pca = pca.transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "\n",
    "################################\n",
    "\n",
    "#\n",
    "\n",
    "#  SVC and error analysis\n",
    "\n",
    "#\n",
    "\n",
    "################################\n",
    "\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "\n",
    "scores = ['precision', 'recall']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "\n",
    "print \"Fitting the classifier to the training set\"\n",
    "t0 = time()\n",
    "clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5,scoring='%s_weighted' % score)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "print \"done in %0.3fs\" % (time() - t0)\n",
    "\n",
    "y_pred = clf.predict(X_test_pca)\n",
    "print classification_report(y_test,y_pred)\n",
    "print confusion_matrix(y_test,y_pred)\n",
    "\n",
    "#################################\n",
    "\n",
    "#\n",
    "\n",
    "# plot \n",
    "\n",
    "#\n",
    "\n",
    "################################\n",
    "\n",
    "\n",
    "def plot_gallery(images, titles, h, w, n_row=3, n_col=4):\n",
    "    \"\"\"Helper function to plot a gallery of images\"\"\"\n",
    "    pl.figure(figsize=(1.8 * n_col, 2.4 * n_row))\n",
    "    pl.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    for i in range(n_row * n_col):\n",
    "        pl.subplot(n_row, n_col, i + 1)\n",
    "        pl.imshow(images[i].reshape((h, w)), cmap=pl.cm.gray)\n",
    "        pl.title(titles[i], size=12)\n",
    "        pl.xticks(())\n",
    "        pl.yticks(())\n",
    "\n",
    "def title(y_pred,y_test,i):\n",
    "    return 'predicted:{},real:{} '.format(y_pred[i],y_test[i])\n",
    "\n",
    "prediction_titles = [title(y_pred, y_test,i) for i in range(12)]\n",
    "\n",
    "plot_gallery(X_test[:12],prediction_titles,h,w)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
